{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer Strean Hatchet Technical Test \n",
    "<br>\n",
    "\n",
    "Hello Stream Hatchet Crew! I hope you enjoy this: \n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## 1. You are given the following SQL tables:\n",
    "\n",
    "<br>\n",
    "\n",
    "a) streamers: it contains time series data, at a 1-min granularity, of all the channels that broadcast on\n",
    "Twitch. The columns of the table are:\n",
    "\n",
    "<br>\n",
    "\n",
    " * username: Channel username\n",
    " * timestamp: Epoch timestamp, in seconds, corresponding to the moment the data was captured\n",
    " * game: Name of the game that the user was playing at that time\n",
    " * viewers: Number of concurrent viewers that the user had at that time\n",
    " * followers: Number of total followers that the channel had at that time\n",
    "\n",
    "<br>\n",
    "\n",
    "b) games_metadata: it contains information of all the games that have ever been broadcasted on Twitch.\n",
    "The columns of the table are:\n",
    "\n",
    "<br>\n",
    "\n",
    "* game: Name of the game\n",
    "* release_date: Timestamp, in seconds, corresponding to the date when the game was released\n",
    "* publisher: Publisher of the game\n",
    "* genre: Genre of the game\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "I am using a DBeaver Sample DataBase in order to see my results! <br>\n",
    "I created both tables as following:\n",
    "\n",
    "<br>\n",
    "\n",
    "```mysql\n",
    "\n",
    "CREATE TABLE `streamers` (\n",
    "  `username` varchar(64) NOT NULL,\n",
    "  `timestamp` datetime NOT NULL,\n",
    "  `game` varchar(32) NOT NULL,\n",
    "  `viewers` integer NOT NULL,\n",
    "  `followers` integer NOT NULL\n",
    "  \n",
    ");\n",
    "\n",
    "\n",
    "\n",
    "CREATE TABLE `games_metadata`(\n",
    "\n",
    "    `game` varchar(64) NOT NULL,\n",
    "    `release_date` datetime NOT NULL, \n",
    "    `publisher` varchar(64) NOT NULL, \n",
    "    `genre` varchar(64) \n",
    "\n",
    ");\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Write an SQL query to:\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 1. Obtain, for each month of 2018, how many streamers broadcasted on Twitch and how many hours of content were broadcasted. The output should contain **month**, **unique_streamers** and **hours_broadcast**.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "```mysql \n",
    "\n",
    "SELECT  strftime('%m',`timestamp`) AS months ,COUNT(DISTINCT username)AS `unique_streamers`, COUNT( strftime('%M',`timestamp`))/(60*1.0) as hours_broadcast\n",
    "FROM streamers where strftime('%Y',`timestamp`) = '2018'\n",
    "GROUP BY months \n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "So first we select the month with the strftime function for the month display (and to later aggregate the data by month), since we only want the months of 2018, we specify the timestamp year for 2018 in the **FROM** statement. <br>\n",
    "We use **COUNT (DISTINCT username)** in order to obtain the total number of different streamers that will be aggregated by the months column we created beforehand.<br>     \n",
    "The data is captured on a per minute basis, duplicated timestamps are valid sicne you'll most likely have multiple streams at the same time.<br>\n",
    "My approach was to count all rows ( duplicate included.The datetime format doesn't matter since this is a time series with 1 minute granularity), and divide it by 60 to get the number of hours.       \n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 2. Obtain the Top 10 streamers that have percentually gained more followers during January 2019, and that primarily stream FPS games. The output should contain the **username** and **follower_growth**.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "```mysql\n",
    "\n",
    "SELECT username, ((MAX(followers)*1.0-MIN(followers)*1.0)/MIN(followers)*1.0) AS follower_growth FROM (SELECT username,followers, genre, \"timestamp\" FROM (SELECT *\n",
    "FROM streamers AS A INNER JOIN games_metadata AS B ON A.game = B.game) \n",
    "WHERE strftime('%Y',\"timestamp\") = '2019' and strftime('%m',\"timestamp\") = '01' and genre = 'FPS')   \n",
    "GROUP BY username\n",
    "Order by follower_growth DESC\n",
    "LIMIT 10 \n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "The first thing we need to do is a inner join table to dintiguish FPS from non FPS games.<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "**SELECT *\n",
    "FROM streamers AS A INNER JOIN games_metadata AS B ON A.game = B.game)**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Now we do a subquery on the the table we just \"created\", where we select what we need: **username** to later display and also to group by ,**followers** to calculate the growth , **genre** to use as a condition for FPS games,**timestamp** to filter only Jan of 2019.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "With this \"newly created table\" ( it's not a table it's only a query, but we can think of it as a table because we are gonna query from a query), and we use:\n",
    "\n",
    "<br>\n",
    "\n",
    "**WHERE strftime('%Y',\"timestamp\") = '2019' and strftime('%m',\"timestamp\") = '01' and genre = 'FPS')**\n",
    "\n",
    "<br>\n",
    "\n",
    "To filter Jan 2019 and FPS games \n",
    "\n",
    "<br>\n",
    "\n",
    "**SELECT username, ((MAX(followers)*1.0-MIN(followers)*1.0)/MIN(followers)*1.0) AS follower_growth**\n",
    "\n",
    "<br>\n",
    "\n",
    "To calculate growth we used the formula above ( multiplication by 1.0 to typecast to decimal) \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**GROUP BY username Order by follower_growth DESC LIMIT 10**\n",
    "\n",
    "<br>\n",
    "\n",
    "and ofcourse we need to aggregate and order the data as requested.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### 3. Obtain the Top 10 publishers that have been watched the most during the first quarter of 2019. The output should contain publisher and hours_watched.\n",
    "\n",
    "<br>\n",
    "\n",
    "##### Note: Hours watched can be defined as the total amount of hours watched by all the viewers combined. Ie: 10 viewers watching for 2 hours will generate 20 Hours Watched.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "```mysql\n",
    "\n",
    "SELECT publisher, (cast(strftime('%m', \"timestamp\") as integer) + 2) / 3 as quarter, COUNT((strftime('%M',`timestamp`)/(60*1.0)) * viewers) as total_hours_watch\n",
    "FROM streamers AS A INNER JOIN games_metadata AS B ON A.game = B.game \n",
    "WHERE quarter = 1\n",
    "GROUP BY publisher \n",
    "ORDER BY total_hours_watch DESC\n",
    "LIMIT 10 ;\n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "*Imagine a new streaming platform has recently launched. They provide an API endpoint that allows\n",
    "third-parties to obtain, at any given time, the list of all the channels broadcasting in the platform, how\n",
    "many concurrent viewers each channel has, what game is each channel playing, etc.<br>\n",
    "At Stream Hatchet we want to capture that information and offer it to our clients through our web app,\n",
    "providing rankings of top-performing streamers and games for each day, week, month, etc. <br>\n",
    "Explain, in detail, how would you design and implement a system that is able to achieve that. From the\n",
    "data gathering to serving the information to the web app so that the end user can consume it, detail\n",
    "how you would implement each step, focusing on scalability and reliability.<br>\n",
    "Describe what specific technologies, frameworks, and tools you would use and how you would deploy\n",
    "the system on a cloud-native infrastructure.*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br> \n",
    "\n",
    "In this question apart from detailing how I would implement the system, I'm gonna go over some theory about API's.\n",
    "\n",
    "\n",
    "### What is an API ?\n",
    "\n",
    "<br>\n",
    "\n",
    "A quick wikipedia search leads us [here](https://en.wikipedia.org/wiki/Application_programming_interface): <br>\n",
    "\n",
    "\n",
    "\n",
    "*An application programming interface (API) is an interface or communication protocol between a client and a server intended to simplify the building of client-side software. It has been described as a “contract” between the client and the server, such that if the client makes a request in a specific format, it will always get a response in a specific format or initiate a defined action.*\n",
    "\n",
    "<br>\n",
    "\n",
    "There exists a famous analogy to explain API's. Imagine you are in a sitting in a restaurant,how do you fill your apetite?<br>\n",
    "Most cases you have a Menu to choose from, in practice you don't really know how each plate is made and honestly you don't really care either, you are just hungry and you want to eat a meal that contains preferably ingreedients to which you are not allergic. <br>\n",
    "An API is the messenger(menu) that takes requests(orders) and tells the system what to do (which plate to cook).<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "APIs are hosted on web servers. When you type www.google.com in your browser’s address bar, your computer is actually asking the www.google.com server for a webpage, which it then returns to your browser.<br>\n",
    "APIs work much the same way, except instead of your web browser asking for a webpage, your program asks for data.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "## Data gathering \n",
    "\n",
    "<br>\n",
    "\n",
    "For data gathering I would use python programming language with  the famous requests library. <br>\n",
    "\n",
    "There are many different types of requests. The most commonly used one, a GET request, is used to retrieve data.(Which is what we want). <br> <br>\n",
    "\n",
    "Here I present a brief tutorial of how I would implement it, by getting data from the ISS(International Space Station),the way one would implement for a streaming platform would be very similar. \n",
    "\n",
    "\n",
    "\n",
    "https://datarebellion.com/blog/easily-build-and-deploy-your-first-python-web-app/\n",
    "\n",
    "https://coderbook.com/@marcus/how-scalable-are-websites-built-in-django-framework/\n",
    "\n",
    "https://www.freecodecamp.org/news/what-is-an-api-in-english-please-b880a3214a82/\n",
    "\n",
    "https://www.howtogeek.com/343877/what-is-an-api/\n",
    "\n",
    "https://www.youtube.com/watch?v=tI8ijLpZaHk\n",
    "\n",
    "https://www.dataquest.io/blog/python-api-tutorial/\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GET request to retrieve information from the OpenNotify API.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "\n",
    "\n",
    "response = requests.get(\"http://api.open-notify.org/iss-now.json\")\n",
    "\n",
    "# Print the status code of the response.\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we are connected to the API.\n",
    "\n",
    "<br>\n",
    "\n",
    "Each status code means something: <br>\n",
    "\n",
    "\n",
    "\n",
    "* 200 — everything went okay, and the result has been returned (if any)\n",
    "* 301 — the server is redirecting you to a different endpoint. This can happen when a company switches domain names, or an endpoint name is changed.\n",
    "* 401 — the server thinks you’re not authenticated. This happens when you don’t send the right credentials to access an API.\n",
    "* 400 — the server thinks you made a bad request. This can happen when you don’t send along the right data, among other things.\n",
    "* 403 — the resource you’re trying to access is forbidden — you don’t have the right permissions to see it.\n",
    "* 404 — the resource you tried to access wasn’t found on the server.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\")\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the server thinks you made a bad request, as stated above it probably means that you are not sending the right data along with the request!<br>\n",
    "If you look into the [API Documentation](http://open-notify.org/Open-Notify-API/), you'll see that the ISS-PASS endpoint requires two paramenters!<br>\n",
    "<br>\n",
    "The ISS Pass endpoint returns when the ISS will next pass over a given location on earth, to do this you need ofcourse the lat and long of your chosen location!<br>\n",
    "<br>\n",
    "You can input the parameters directly into the URL as follows http://api.open-notify.org/iss-pass.json?lat=40.71&lon=-74 or setup the parameters as a dictionary!\n",
    "<br>\n",
    "Since we are in Barcelona(41.3851° N, 2.1734° E) let's see when the ISS will hoover over us!  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"message\": \"success\", \\n  \"request\": {\\n    \"altitude\": 100, \\n    \"datetime\": 1567980618, \\n    \"latitude\": 41.3851, \\n    \"longitude\": 2.1734, \\n    \"passes\": 5\\n  }, \\n  \"response\": [\\n    {\\n      \"duration\": 569, \\n      \"risetime\": 1567982248\\n    }, \\n    {\\n      \"duration\": 646, \\n      \"risetime\": 1567987994\\n    }, \\n    {\\n      \"duration\": 589, \\n      \"risetime\": 1567993857\\n    }, \\n    {\\n      \"duration\": 575, \\n      \"risetime\": 1567999726\\n    }, \\n    {\\n      \"duration\": 637, \\n      \"risetime\": 1568005541\\n    }\\n  ]\\n}\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the parameters we want to pass to the API.\n",
    "# This is the latitude and longitude of New York City.\n",
    "parameters = {\"lat\": 41.3851, \"lon\": 2.1734}\n",
    "# Make a get request with the parameters.\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\", params=parameters)\n",
    "# Print the content of the response (the data the server returned)\n",
    "display(response.content.decode(\"utf-8\"))\n",
    "\n",
    "\n",
    "print(\"\\n \\n \\n\")\n",
    "\n",
    "\n",
    "\n",
    "type(response.content.decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the server returns us with a string.<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Strings are the way that we pass information back and forth to APIs, but it’s hard to get the information we want out of them.<br>\n",
    "There's a much better way of getting data and it's trought json files.<br><br>\n",
    " JSON is a way to encode data structures like lists and dictionaries to strings that ensures that they are easily readable by machines, JSON is the primary format in which data is passed back and forth to APIs, and most API servers will send their responses in JSON format.<br><br>\n",
    "Python supports JSON trough an inbuilt module called json.<br><br>\n",
    " \n",
    "The json module converts lists and dics to JSON, and strings to lists and dictionaries,in order to do this the module has 2 main methods:\n",
    "\n",
    "  * **dumps** — Takes in a Python object, and converts it to a string.\n",
    "  * **loads** — Takes a JSON string, and converts it to a Python object.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    " \n",
    "### Getting JSON from an API request \n",
    "You can get the content of a response as a python object by using the .json() method on the response.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'message': 'success', 'request': {'altitude': 100, 'datetime': 1567980618, 'latitude': 41.3851, 'longitude': 2.1734, 'passes': 5}, 'response': [{'duration': 569, 'risetime': 1567982248}, {'duration': 646, 'risetime': 1567987994}, {'duration': 589, 'risetime': 1567993857}, {'duration': 575, 'risetime': 1567999726}, {'duration': 637, 'risetime': 1568005541}]}\n"
     ]
    }
   ],
   "source": [
    "# Make the same request we did earlier, but with the coordinates of San Francisco instead.\n",
    "parameters = {\"lat\":41.3851, \"lon\": 2.1734}\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\", params=parameters)\n",
    "# Get the response data as a python object. Verify that it's a dictionary.\n",
    "data = response.json()\n",
    "print(type(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(data['request']['altitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content type \n",
    "<br>\n",
    "\n",
    "We can also access the response metadata, that contains information on how the data was generated and how to decode it,this metadata is stored in the response headers, we can access it through the headers method.\n",
    "<br>\n",
    "\n",
    "The headers method returns a dictionary,the most relevant key-pair for extracting data is the 'Content-Type', since it tells you which type of data the server returns to you.(In this case is a Json file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Server': 'nginx/1.10.3', 'Date': 'Sun, 08 Sep 2019 22:13:58 GMT', 'Content-Type': 'application/json', 'Content-Length': '522', 'Connection': 'keep-alive', 'Via': '1.1 vegur'}\n",
      "application/json\n"
     ]
    }
   ],
   "source": [
    "# Headers is a dictionary\n",
    "print(response.headers)\n",
    "# Get the content-type from the dictionary.\n",
    "print(response.headers[\"content-type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Stream Hatchet Streaming use case \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Well if we'd be getting data from the streaming service throught an API, the process will be very similar to what we did above! <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "   1. Read the API documenation and see which parameters(if any)  would be necessary to be inputted.\n",
    "   2. Get request from the streaming service API. \n",
    "   3. Look into the response metadata first, to see the data type.(most likely would be JSON)\n",
    "   4. And finnaly get the data response with the json method(if it's a json file), and save it.\n",
    "   \n",
    "   \n",
    "<br>\n",
    "\n",
    "### Deployment \n",
    "\n",
    "<br>\n",
    "\n",
    "Since we want to deploy on a cloud native infrastructure focusing on scalability and reliability,I'd use Docker for containerization, and Kubernetes as container-orchestration tool.<br>\n",
    "\n",
    "So I would create a Docker Container to run our system,make a Docker Image  after, our system is ready to be deployed and managed with Kubernetes.\n",
    "\n",
    "\n",
    "### What is Docker and Kubernetes? \n",
    "\n",
    "<br>\n",
    "\n",
    "Docker is a standalone software that can be installed on any computer to run containerized applications. Containerization is an approach of running applications on an OS such that the application is isolated from the rest of the system. You create an illusion for your application that it is getting its very own OS instance, although there may be other containers running on same system. Docker is what enables us to run, create and manage containers on a single operating system.<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Kubernetes turns it up to 11, so to speak. If you have Docker installed on a bunch of hosts (different operating systems), you can leverage Kubernetes. These nodes, or Docker hosts, can be bare-metal servers or virtual machines. Kubernetes can then allow you to automate container provisioning, networking, load-balancing, security and scaling across all these nodes from a single command line or dashboard. A collection of nodes that is managed by a single Kubernetes instance is referred to as a Kubernetes cluster.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Why Kubernetes Solution?**\n",
    "\n",
    "<br>\n",
    "\n",
    "   1. To make the infrastructure more robust: Application will be online, even if some of the nodes go offline, i.e, Reliability \n",
    "   2. To make application more scalable: If workload increases, simply spawn more containers and/or add more nodes to your Kubernetes cluster.\n",
    "\n",
    "<br>\n",
    "\n",
    "Kubernetes works with Amazon EC2, Azure Container Service, Rackspace, GCE, IBM Software, and other clouds. And it works with bare-metal (using something like CoreOS), Docker, and vSphere. And it works with libvirt and KVM, which are Linux machines turned into hypervisors (i.e, a platform to run virtual machines). <br>\n",
    "This way you don't need to be stuck with a specific cloud vendor. \n",
    "\n",
    "  \n",
    "  \n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "https://thenewstack.io/cloud-native-apps-need-to-be-managed-in-a-completely-new-way/   \n",
    "\n",
    "https://medium.com/better-practices/deploying-a-scalable-web-application-with-docker-and-kubernetes-a5000a06c4e9\n",
    "\n",
    "https://kubernetes.io/\n",
    "\n",
    "https://containerjournal.com/topics/container-ecosystems/kubernetes-vs-docker-a-primer/\n",
    "\n",
    "http://www.developintelligence.com/blog/2017/02/kubernetes-actually-use/\n",
    "\n",
    "https://www.scalyr.com/blog/create-docker-image/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
