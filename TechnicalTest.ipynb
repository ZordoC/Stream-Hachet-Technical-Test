{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer Strean Hatchet Technical Test \n",
    "<br>\n",
    "\n",
    "Hello Stream Hatchet Crew! I hope you enjoy this: \n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "****\n",
    "\n",
    "## 1. You are given the following SQL tables:\n",
    "\n",
    "<br>\n",
    "\n",
    "a) streamers: it contains time series data, at a 1-min granularity, of all the channels that broadcast on\n",
    "Twitch. The columns of the table are:\n",
    "\n",
    "<br>\n",
    "\n",
    " * username: Channel username\n",
    " * timestamp: Epoch timestamp, in seconds, corresponding to the moment the data was captured\n",
    " * game: Name of the game that the user was playing at that time\n",
    " * viewers: Number of concurrent viewers that the user had at that time\n",
    " * followers: Number of total followers that the channel had at that time\n",
    "\n",
    "<br>\n",
    "\n",
    "b) games_metadata: it contains information of all the games that have ever been broadcasted on Twitch.\n",
    "The columns of the table are:\n",
    "\n",
    "<br>\n",
    "\n",
    "* game: Name of the game\n",
    "* release_date: Timestamp, in seconds, corresponding to the date when the game was released\n",
    "* publisher: Publisher of the game\n",
    "* genre: Genre of the game\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "I am using a DBeaver Sample DataBase in order to see my results! <br>\n",
    "I created both tables as following:\n",
    "\n",
    "<br>\n",
    "\n",
    "```mysql\n",
    "\n",
    "CREATE TABLE `streamers` (\n",
    "  `username` varchar(64) NOT NULL,\n",
    "  `timestamp` datetime NOT NULL,\n",
    "  `game` varchar(32) NOT NULL,\n",
    "  `viewers` integer NOT NULL,\n",
    "  `followers` integer NOT NULL\n",
    "  \n",
    ");\n",
    "\n",
    "\n",
    "\n",
    "CREATE TABLE `games_metadata`(\n",
    "\n",
    "    `game` varchar(64) NOT NULL,\n",
    "    `release_date` datetime NOT NULL, \n",
    "    `publisher` varchar(64) NOT NULL, \n",
    "    `genre` varchar(64) \n",
    "\n",
    ");\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Write an SQL query to:\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 1. Obtain, for each month of 2018, how many streamers broadcasted on Twitch and how many hours of content were broadcasted. The output should contain **month**, **unique_streamers** and **hours_broadcast**.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "```mysql \n",
    "\n",
    "SELECT  strftime('%m',`timestamp`) AS months ,COUNT(DISTINCT username)AS `unique_streamers`, COUNT( strftime('%M',`timestamp`))/(60*1.0) as hours_broadcast\n",
    "FROM streamers where strftime('%Y',`timestamp`) = '2018'\n",
    "GROUP BY months \n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "So first we select the month with the strftime function for the month display (and to later aggregate the data by month), since we only want the months of 2018, we specify the timestamp year for 2018 in the **FROM** statement. <br>\n",
    "We use **COUNT (DISTINCT username)** in order to obtain the total number of different streamers that will be aggregated by the months column we created beforehand.<br>     \n",
    "The data is captured on a per minute basis, duplicated timestamps are valid sicne you'll most likely have multiple streams at the same time.<br>\n",
    "My approach was to count all rows ( duplicate included.The datetime format doesn't matter since this is a time series with 1 minute granularity), and divide it by 60 to get the number of hours.       \n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 2. Obtain the Top 10 streamers that have percentually gained more followers during January 2019, and that primarily stream FPS games. The output should contain the **username** and **follower_growth**.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "```mysql\n",
    "\n",
    "SELECT username, ((MAX(followers)*1.0-MIN(followers)*1.0)/MIN(followers)*1.0) AS follower_growth FROM (SELECT username,followers, genre, \"timestamp\" FROM (SELECT *\n",
    "FROM streamers AS A INNER JOIN games_metadata AS B ON A.game = B.game) \n",
    "WHERE strftime('%Y',\"timestamp\") = '2019' and strftime('%m',\"timestamp\") = '01' and genre = 'FPS')   \n",
    "GROUP BY username\n",
    "Order by follower_growth DESC\n",
    "LIMIT 10 \n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "The first thing we need to do is a inner join table to dintiguish FPS from non FPS games.<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "**SELECT *\n",
    "FROM streamers AS A INNER JOIN games_metadata AS B ON A.game = B.game)**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Now we do a subquery on the the table we just \"created\", where we select what we need: **username** to later display and also to group by ,**followers** to calculate the growth , **genre** to use as a condition for FPS games,**timestamp** to filter only Jan of 2019.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "With this \"newly created table\" ( it's not a table it's only a query, but we can think of it as a table because we are gonna query from a query), and we use:\n",
    "\n",
    "<br>\n",
    "\n",
    "**WHERE strftime('%Y',\"timestamp\") = '2019' and strftime('%m',\"timestamp\") = '01' and genre = 'FPS')**\n",
    "\n",
    "<br>\n",
    "\n",
    "To filter Jan 2019 and FPS games \n",
    "\n",
    "<br>\n",
    "\n",
    "**SELECT username, ((MAX(followers)*1.0-MIN(followers)*1.0)/MIN(followers)*1.0) AS follower_growth**\n",
    "\n",
    "<br>\n",
    "\n",
    "To calculate growth we used the formula above ( multiplication by 1.0 to typecast to decimal) \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**GROUP BY username Order by follower_growth DESC LIMIT 10**\n",
    "\n",
    "<br>\n",
    "\n",
    "and ofcourse we need to aggregate and order the data as requested.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### 3. Obtain the Top 10 publishers that have been watched the most during the first quarter of 2019. The output should contain publisher and hours_watched.\n",
    "\n",
    "<br>\n",
    "\n",
    "##### Note: Hours watched can be defined as the total amount of hours watched by all the viewers combined. Ie: 10 viewers watching for 2 hours will generate 20 Hours Watched.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "```mysql\n",
    "\n",
    "SELECT publisher, (cast(strftime('%m', \"timestamp\") as integer) + 2) / 3 as quarter, COUNT((strftime('%M',`timestamp`)/(60*1.0)) * viewers) as total_hours_watch\n",
    "FROM streamers AS A INNER JOIN games_metadata AS B ON A.game = B.game \n",
    "WHERE quarter = 1\n",
    "GROUP BY publisher \n",
    "ORDER BY total_hours_watch DESC\n",
    "LIMIT 10 ;\n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "****\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "*\"Imagine a new streaming platform has recently launched. They provide an API endpoint that allows\n",
    "third-parties to obtain, at any given time, the list of all the channels broadcasting in the platform, how\n",
    "many concurrent viewers each channel has, what game is each channel playing, etc.<br>\n",
    "At Stream Hatchet we want to capture that information and offer it to our clients through our web app,\n",
    "providing rankings of top-performing streamers and games for each day, week, month, etc. <br>\n",
    "Explain, in detail, how would you design and implement a system that is able to achieve that. From the\n",
    "data gathering to serving the information to the web app so that the end user can consume it, detail\n",
    "how you would implement each step, focusing on scalability and reliability.<br>\n",
    "Describe what specific technologies, frameworks, and tools you would use and how you would deploy\n",
    "the system on a cloud-native infrastructure.\"*\n",
    "\n",
    "<br>\n",
    "<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=skc-ZEU9kO8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To solve this problem I would  implement a **Background Job**! With Heroku's **Worker Dyno**.\n",
    " \n",
    "<br>\n",
    "\n",
    "Background jobs can **dramatically improve the scalability of a web app** by enabling it to offload slow or CPU-intensive tasks from its front-end. This helps ensure that the front-end can handle incoming web requests promptly, reducing the likelihood of performance issues that occur when requests become backlogged.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### **When do we use Background Jobs?**\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    " * **Communicating with an external API or service**\n",
    " \n",
    " <br>\n",
    " \n",
    " * Performing resource-intensive data manipulation, such as image or video processing\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### **Order of operations** <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "The following are the high-level steps for handling a request that uses a background job:<br><br><br>\n",
    "\n",
    "   1. A client sends an app a request to perform a task that is well suited to a background job.<br><br>\n",
    "   2. The appâ€™s front-end (known on Heroku as the web process) receives the request. It adds the task to a job queue and immediately responds to the client. The response indicates that the result of the request is pending, and it optionally includes a URL the client can use to poll for the result.<br><br>\n",
    "   3.  A separate app process (known on Heroku as a worker process) notices that a task was added to the job queue. It takes the task off of the queue and begins performing it.<br><br>\n",
    "   4.  When the worker process completes the task, it persists the outcome of the task. For example, in the case of uploading a file to Amazon S3, it might persist the fileâ€™s S3 URL.<br><br>\n",
    "   5.  The client polls the app on a regular basis until the task is completed and the result is obtained.<br><br>\n",
    "   \n",
    "   \n",
    "   \n",
    "To implement this system with python programming language I would use **RQ(Redis Queue)** library with a **Redis Server**!  \n",
    "\n",
    "<br>\n",
    "\n",
    "* **RQ (Redis Queue) is a simple Python library for queueing jobs and processing them in the background with workers. It is backed by Redis and it is designed to have a low barrier to entry. It can be integrated in your web stack easily.**\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "   \n",
    "Configuration is easy just use the following command:\n",
    "\n",
    "<br>\n",
    "   \n",
    "```sh \n",
    "pip install rq\n",
    "```\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Next we create a **worker** script ! And this worker script will listen to queued tasks and process them as they are received\n",
    "\n",
    "<br>\n",
    "\n",
    "Then we'd just create a module to request data from the API! \n",
    "\n",
    "<br>\n",
    "\n",
    "## Data gathering \n",
    "\n",
    "<br>\n",
    "\n",
    "For the data gathering part, i'd just use python's **request** library, here follows an example to get data from the ISS's API. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GET request to retrieve information from the OpenNotify API. \n",
    "<br>\n",
    "\n",
    "Here I show a little tutorial on how to request the data from an API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "\n",
    "\n",
    "response = requests.get(\"http://api.open-notify.org/iss-now.json\")\n",
    "\n",
    "# Print the status code of the response.\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we are connected to the API.\n",
    "\n",
    "<br>\n",
    "\n",
    "Each status code means something: <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "* 200 â€” everything went okay, and the result has been returned (if any)\n",
    "* 301 â€” the server is redirecting you to a different endpoint. This can happen when a company switches domain names, or an endpoint name is changed.\n",
    "* 401 â€” the server thinks youâ€™re not authenticated. This happens when you donâ€™t send the right credentials to access an API.\n",
    "* 400 â€” the server thinks you made a bad request. This can happen when you donâ€™t send along the right data, among other things.\n",
    "* 403 â€” the resource youâ€™re trying to access is forbidden â€” you donâ€™t have the right permissions to see it.\n",
    "* 404 â€” the resource you tried to access wasnâ€™t found on the server.\n",
    "\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\")\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the server thinks you made a bad request, as stated above it probably means that you are not sending the right data along with the request!<br>\n",
    "If you look into the [API Documentation](http://open-notify.org/Open-Notify-API/), you'll see that the ISS-PASS endpoint requires two paramenters!<br>\n",
    "<br>\n",
    "The ISS Pass endpoint returns when the ISS will next pass over a given location on earth, to do this you need ofcourse the lat and long of your chosen location!<br>\n",
    "<br>\n",
    "You can input the parameters directly into the URL as follows http://api.open-notify.org/iss-pass.json?lat=40.71&lon=-74 or setup the parameters as a dictionary!\n",
    "<br>\n",
    "Since we are in Barcelona(41.3851Â° N, 2.1734Â° E) let's see when the ISS will hoover over us!  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"message\": \"success\", \\n  \"request\": {\\n    \"altitude\": 100, \\n    \"datetime\": 1568206691, \\n    \"latitude\": 41.3851, \\n    \"longitude\": 2.1734, \\n    \"passes\": 5\\n  }, \\n  \"response\": [\\n    {\\n      \"duration\": 608, \\n      \"risetime\": 1568238441\\n    }, \\n    {\\n      \"duration\": 638, \\n      \"risetime\": 1568244221\\n    }, \\n    {\\n      \"duration\": 577, \\n      \"risetime\": 1568250095\\n    }, \\n    {\\n      \"duration\": 584, \\n      \"risetime\": 1568255953\\n    }, \\n    {\\n      \"duration\": 646, \\n      \"risetime\": 1568261761\\n    }\\n  ]\\n}\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the parameters we want to pass to the API.\n",
    "# This is the latitude and longitude of Barcelona.\n",
    "parameters = {\"lat\": 41.3851, \"lon\": 2.1734}\n",
    "# Make a get request with the parameters.\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\", params=parameters)\n",
    "# Print the content of the response (the data the server returned)\n",
    "display(response.content.decode(\"utf-8\"))\n",
    "\n",
    "\n",
    "print(\"\\n \\n \\n\")\n",
    "\n",
    "\n",
    "\n",
    "type(response.content.decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the server returns us with a string.<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Strings are the way that we pass information back and forth to APIs, but itâ€™s hard to get the information we want out of them.<br>\n",
    "There's a much better way of getting data and it's trought json files.<br><br>\n",
    " JSON is a way to encode data structures like lists and dictionaries to strings that ensures that they are easily readable by machines, JSON is the primary format in which data is passed back and forth to APIs, and most API servers will send their responses in JSON format.<br><br>\n",
    "Python supports JSON trough an inbuilt module called json.<br><br>\n",
    " \n",
    "The json module converts lists and dics to JSON, and strings to lists and dictionaries,in order to do this the module has 2 main methods:\n",
    "\n",
    "  * **dumps** â€” Takes in a Python object, and converts it to a string.\n",
    "  * **loads** â€” Takes a JSON string, and converts it to a Python object.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    " \n",
    "### Getting JSON from an API request \n",
    "You can get the content of a response as a python object by using the .json() method on the response.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'message': 'success', 'request': {'altitude': 100, 'datetime': 1568206691, 'latitude': 41.3851, 'longitude': 2.1734, 'passes': 5}, 'response': [{'duration': 608, 'risetime': 1568238441}, {'duration': 638, 'risetime': 1568244221}, {'duration': 577, 'risetime': 1568250095}, {'duration': 584, 'risetime': 1568255953}, {'duration': 646, 'risetime': 1568261761}]}\n"
     ]
    }
   ],
   "source": [
    "# Make the same request we did earlier, but with the coordinates of San Francisco instead.\n",
    "parameters = {\"lat\":41.3851, \"lon\": 2.1734}\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\", params=parameters)\n",
    "# Get the response data as a python object. Verify that it's a dictionary.\n",
    "data = response.json()\n",
    "print(type(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(data['request']['altitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content type \n",
    "<br>\n",
    "\n",
    "We can also access the response metadata, that contains information on how the data was generated and how to decode it,this metadata is stored in the response headers, we can access it through the headers method.\n",
    "<br>\n",
    "\n",
    "The headers method returns a dictionary,the most relevant key-pair for extracting data is the 'Content-Type', since it tells you which type of data the server returns to you.(In this case is a Json file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Server': 'nginx/1.10.3', 'Date': 'Wed, 11 Sep 2019 12:58:11 GMT', 'Content-Type': 'application/json', 'Content-Length': '522', 'Connection': 'keep-alive', 'Via': '1.1 vegur'}\n",
      "application/json\n"
     ]
    }
   ],
   "source": [
    "# Headers is a dictionary\n",
    "print(response.headers)\n",
    "# Get the content-type from the dictionary.\n",
    "print(response.headers[\"content-type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we'd make an API request and save it as a module to call on the worker process.\n",
    "<br>\n",
    "\n",
    "In your application, we **create a RQ queue**.\n",
    "<br>\n",
    "\n",
    "And enqueue the function call(our GET request) :\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "# Deployment\n",
    "\n",
    "<br>\n",
    "\n",
    "Add the worker process to the Procfile in the root of the project.\n",
    "\n",
    "<br>\n",
    "\n",
    "Then, provision an instance of Redis with the Redis To Go addon and deploy with a git push.\n",
    "\n",
    "\n",
    "```shell\n",
    "\n",
    "\n",
    "$ heroku addons:create redistogo\n",
    "\n",
    "\n",
    "$ git push heroku master\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "<br>\n",
    "Once everythingâ€™s pushed up you can scale your workers according to your needs:\n",
    "\n",
    "```shell\n",
    "heroku scale worker=1\n",
    "```\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "The same could also be achieved with Celery, there are many ways of implementing a system like this, and it also depends on which cloud our web app is hosted and the framework's used for it's backend!\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "****\n",
    "<br><br>\n",
    "# 3.\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "*\"A 4-year-old is trying to build a tub for his goldfish out of Lego. Every Lego piece is stuck to the piece to\n",
    "its left and its right (except for the first and last one). All the pieces have a width of 1 unit.\n",
    "<br>Write a program, using the programming language of your choice, that given the heights (in units) of the\n",
    "lego pieces from left to right, outputs the total amount of water held over the pieces that the kid built.\"*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<br><br>\n",
    "\n",
    "\n",
    "For this question I decided to make a short 5 minute youtube clip, detailing my approach, I hope you enjoy it! \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[<img src=\"youtubesnap.png\">](https://www.youtube.com/channel/UCW6qBfYgb-w1EiplkuQf9hA?view_as=subscriber)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Implementation:\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min_rl_lr(*args):\n",
    "    \"\"\"\n",
    "    Given a number of values specified by the user\n",
    "    returns the a list with the biggest elements updated from right to left, \n",
    "    and from left to right.\n",
    "    \n",
    "    ie - input [3,1,3,4]\n",
    "    \n",
    "    outputs : rl = [3,3,3,4]\n",
    "            : lr = [4,4,4,4]\n",
    "    \n",
    "    :param *args: int  \n",
    "    :return: rl , lr , lists \n",
    "     \n",
    "    \"\"\"\n",
    "    rl = list() # list of maximum right to left \n",
    "    lr = list() # list of maximum left to right \n",
    "    big_rl = None # holder for max value\n",
    "    big_lr = None # holder for max value\n",
    "    og =  list(args)\n",
    "    for w in args: # Loops through the arguments\n",
    "       \n",
    "        # condition if holder is 0,(beggning of the loop) appends the first value \n",
    "        # or if current element is bigger than holder, holder becomes the new value  \n",
    "        if big_rl is None or w > big_rl: big_rl = w \n",
    "            \n",
    "        rl.append(big_rl) # appends the \n",
    "            \n",
    "    \n",
    "    # The same as before but with the input inverted \n",
    "    \n",
    "    for w in list(reversed(args)): # list(reversed(args)) , reverses the order of the list, reading left to right\n",
    "    \n",
    "        if big_lr is None or w > big_lr: big_lr = w\n",
    "            \n",
    "        lr.append(big_lr)\n",
    "    \n",
    "    # We need to revert the list again so it's in the \"orignal format\"\n",
    "    \n",
    "    return rl ,list(reversed(lr)) , og \n",
    "    \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_tank(original):\n",
    "    \"\"\"\n",
    "    Draws the original configuration \n",
    "    \n",
    "    :params original: list \n",
    "    \n",
    "    :returns: void\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"\\n Original Configuration is : \\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    for row in range(max(original), 0, -1): # Loops from max of the list to 0, so to get row 3 , row 2, row 1.\n",
    "        print(' '.join(['#' if height >= row else ' ' for height in original])) # prints horizontally a symbol if the height (element of list) => row number  \n",
    "                                                                     # else prints an empty space\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_of_two_lists(l1,l2):\n",
    "    \"\"\"\n",
    "    Given two lists, iterates through both in paralel and stores the minimum\n",
    "    into a new list.\n",
    "    \n",
    "    :param l1: list\n",
    "    :param l2: list\n",
    "    :return: list\n",
    "      \n",
    "    \"\"\"\n",
    "    # list comprenhension, loops through both lists in paralel with the zip function,\n",
    "    # and stores the minimum element per iteration     \n",
    "    \n",
    "    return [min(j) for j in zip(l1,l2)]\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_water(original,minimum):\n",
    "    \"\"\"\n",
    "    Calculates the difference the newly created list that holds the minimum of the right to left and left to right peaks list\n",
    "    with the orignal list of the configuration specified of the user, and calculates the volume of water.\n",
    "    \n",
    "    :param original: list\n",
    "    :param minimum: list\n",
    "    :return: list\n",
    "    \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    \n",
    "    sub_list =list(np.subtract(minimum,original))\n",
    "    \n",
    "    return(np.sum(sub_list),sub_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original Configuration is : \n",
      "\n",
      "#      \n",
      "#     #\n",
      "# # # #\n",
      "\n",
      "Original configuration: [3, 1, 1, 2]\n",
      "\n",
      "\n",
      "Right to left peaks: [3, 3, 3, 3]\n",
      "\n",
      "Left to right peaks: [3, 2, 2, 2]\n",
      "\n",
      "\n",
      "Minimum of [3, 3, 3, 3] and [3, 2, 2, 2] : \n",
      "\n",
      " [3, 2, 2, 2]\n",
      "\n",
      "\n",
      " The total amount of water held by the configuration is : \n",
      " \n",
      " 2\n"
     ]
    }
   ],
   "source": [
    "rl , lr, og =  max_min_rl_lr(3,1,1,2)\n",
    "\n",
    "min_two =  min_of_two_lists(rl,lr)\n",
    "\n",
    "draw_tank(og)\n",
    "\n",
    "\n",
    "print(\"\\nOriginal configuration: {}\".format(og))\n",
    "print(\"\\n\\nRight to left peaks: {}\".format(rl))\n",
    "print(\"\\nLeft to right peaks: {}\".format(lr))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\nMinimum of {} and {} : \\n\\n {}\".format(rl,lr,min_two))\n",
    "\n",
    "water,dif = total_water(og,min_two)\n",
    "\n",
    "print(\"\\n\\n The total amount of water held by the configuration is : \\n \\n {}\".format(water))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "\n",
    "<br>\n",
    "\n",
    "# 4 \n",
    "\n",
    "<br>\n",
    "\n",
    "## a)  Focusing on one or two sections of your choice, explain what insights you can extract from the data that is being represented.  \n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "## **Channel Searcher Section** \n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "I found this section super usefull for streamers that want to take an analytical approach analysis of  their stream performance and for sponsors who are looking for successful streamers to promote out their brand/product! \n",
    "<br>\n",
    "\n",
    "<br>\n",
    "The user with a simple look he can draw a couple of important KPI's such as:\n",
    "\n",
    "<br>\n",
    "\n",
    "*  Which **game** draw's more **viewership**, produces more **followers**, **hours watched**   . \n",
    "\n",
    "*  What's the **best combination of games** to be played in section\n",
    "\n",
    "*  Which is the **best time to stream** a certain game, or just stream overall\n",
    "\n",
    "*  The best **stream titles**  \n",
    "\n",
    "<br>\n",
    "\n",
    "This KPI's can be extracted over different ranges of time, so they could evaluated them by day,week or month. \n",
    "\n",
    "\n",
    "<br> \n",
    "\n",
    "### Shroud Channel Example\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"shroud.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "Here we have a brief statistical summary of the channel performance, for the month of July. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Which is of interest for the streamer as well for potential sponsors!\n",
    "\n",
    "<br> Taking a more detailed look :\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"shroudmetrics.png\">\n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "We can see that the most played game during the month of **August** was **World of Warcraft**,  it also has the most followers and new viewers, however if we take a look at **Call of Duty** the least broadcasted game was the one had the best **Peaks & AVG CCV's** and also recorded **half the number of New followers**  with only **5%** of broadcasted air time compared to **Wow** .\n",
    "\n",
    "<br>\n",
    "\n",
    "With **this information** streamers can choose which games to play in order to **prioritize** the **metric** they wish to improve as well as **measure the impact a game has on the audience**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br><br>\n",
    "\n",
    "## **Rankings Section** \n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "In this section, we can analyse the different KPI's over different platforms ! <br>\n",
    "<br>\n",
    "We know twitch is the main platform for streaming gaming content, but **sometimes sheer viewership** doesn't tell us the whole story!\n",
    "<br>\n",
    "The other performance metrics, can help users evaluate the platform performance in various different ways.For example a sponsor might be more interested in **overall platform statistcs**, while a streamer might have more interest in **per channel statistics**   \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"HoursWatched.png\">\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "A look at the number of unique channels in each platform shows us another perspective:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"UniqueChannels.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft's streaming platform Mixer has showed a steady growth, even overthrowing twitch this past month!! \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "However I'd like to pose a **question**:\n",
    "\n",
    "<br>\n",
    "\n",
    "* **Does more content creators create a more health and active platform?**\n",
    "\n",
    "<br>\n",
    "\n",
    "Using only logic, one would infere that more content creators is always good thing to have.However we can also pose this **question**:\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "* **Is this increase of  active content creators benefiting or hurting the content creators, and the platform itself?**\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"avgCCV_channel.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too much streamers is not such a good thing after all, and it **may** be causing **an AVG CCV per channel of less than 1 viewer**.<br>\n",
    "<br>\n",
    "Facebook has hands down the best values,it has alot less channels than mixer or twitch resulting in a excellent AVG CCV for it's streamers !  <br>\n",
    "\n",
    "\n",
    "<br> \n",
    "<br>\n",
    "And when looking at the most **channel's popular streaming moments,Youtube is on par with twitch**. \n",
    "\n",
    "<br>\n",
    " \n",
    "<img src =\"PeakCCVChannel.png\">\n",
    " \n",
    " \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "To summarise **this section offers different perspectives on channels performance**, and lets the users of **Stream Hatchet's Platform** decide which is the platform more suitable for them! \n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Bonus of ranking section \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**I know that time is precious for you guys at Stream Hatchet, so feel free to skip this!** \n",
    "\n",
    "\n",
    "W\n",
    "\n",
    "<img src=\"average_concurrent_platform.png\">\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "We can see the sheer enourmous impact that twitch has on the streaming scene, aswell as it's consistence growth over the years.\n",
    "It's no surprise Twitch dominates the scene, as it started years before it's main competitors, building a strong brand over the years.<br><br>\n",
    "\n",
    "This has led to having over **1 million more average concurrent vierwes** over it's main competitor Youtube, this is an abysmal difference, we can also note that in 1 year and 9 months,  **Twtich** has **doubled** it's avg cucurrent viewers from **double of youtube's best record (~400k)** to a whooping **1.33570** recorded this August. <br> <br>\n",
    "One interesting season pattern found present over the years of twitch's existence(specially since 2015) seen in **average concurrent viewers** is the **growth** in the **month of January**!This is highly noticable **in 2018** where it had it's **biggest growth ever recorded!**  <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "My first thought was that most **publishers**,in order to maximize their sales,tend to **publish games during Christmas holidays**.However I didn't find   data to support this hypothesis.<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"table.png\">\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "Looking at the performance of the channel ELEAGUE of the month of January 2018, confirms this. \n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src =\"ELEAGUES.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<br> <br> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**My question**: Is ELEAGUES Majors tournament causing a peak CCV in the whole platform, or is this a seasonal holiday pattern? \n",
    "<br><br>\n",
    "<img src =\"PeakJan.png\">\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "The **ELEAGUES CS MAJORS FINALS** took place on Jan 29th, which also corresponds to the highest recorded peak of the month.\n",
    "<br>\n",
    "Now taking a look at the Peak CCV of the whole platform : \n",
    "\n",
    "\n",
    "<img src =\"PeakViewersTwitch.png\">\n",
    "\n",
    "\n",
    "\n",
    "<br> <br> \n",
    "\n",
    "<br>\n",
    "\n",
    "So sponsors and advertisers be aware, sice this may not be a season pattern caused by Holidays! \n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Games Section - Vanilla Wow Analysis ! ( Bonus ) \n",
    "\n",
    "<br>\n",
    "\n",
    "From this section one can derive various insights, mainly the **popularity of a game not only in viewership** but also with the number of **content creators**! I'm gonna analyse the recent resurface of Wow!  \n",
    "\n",
    "<br> \n",
    "\n",
    "In 2018 fortnine has dominated the streaming scene! \n",
    "\n",
    "<br> \n",
    "\n",
    "\n",
    "<img src =\"Top102018.png\">\n",
    "\n",
    "<br>\n",
    "\n",
    "The sheer magnitude of Avg Channels,and Airtime isn't comparable to any other game! There was so much broadcasted content and creators, that Fortnite was hands down the most popular game **not only in viewership** but also with **content creators**!   \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "In **2019, fortnine still dominates** the scene,ranking at number one every month! But something **changed** this past month, something that **fans from all over the world have been craving for years and years**! (me included)   \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Taking a look at the overall statistics of the month of August: \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<img src =\"games_august2019.png\">\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Fortnine still dominates, however **Wow that ranked # 13 in July** suddenly **jumped to # 3** !  \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Aug 19th   to   Aug 25th - Week 34, 2019** Wow was still ranked at **# 11** , with a **share of 2.5%**!!\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<img src =\"Wow#11.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**What happend?** \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "On **26th of August** the greatly anticipated release of the official **Vanilla Wow Servers** happened! <br>\n",
    "\n",
    "Was this a massive disruption on twitch ? **YES**, take a look at next week's data **26th August to 1st September - Week 35, 2019** !\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src =\"26-1Sept.png\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Despite Fortnine having a similar amount of broadcast time,and content creators,**WoW dominated the viewership reach**, with a staggering **difference of 36 Million Hours watched** over Fortnine, and reaching a **22.4% share** over the entire platform!  \n",
    "\n",
    "<br>\n",
    "\n",
    "This past week, recorded over **31 million hours watched** , take notice that in **July fortnine clocked in 88 Million Hours** of content watched! Just this past two weeks **Wow clocked in 83 Million Hours** ! \n",
    "Probably due to the **hype built over the years** for this release, even I an Ex-Wow player, have been dreaming of this day for the past 5-6 years! <br>\n",
    "<br>\n",
    "Vanilla Wow was one of the most important online multiplayer game releases, my theory of this great shift in viewership in the past 2 weeks, is the **nostalgia factor** but is it enough to steal Fortnine's thunder?    \n",
    "\n",
    "<br> \n",
    "<br> \n",
    "\n",
    "##  Does this pose a real threath or it's just hype ? \n",
    "\n",
    "<br> \n",
    "\n",
    "<br>\n",
    "\n",
    "One of Wow biggest problem, is the **dead months** before the release of new content,right now it's hot since it was released two weeks ago, my prediction is that **in time fortnine** will start to **resurface as the biggest player in streaming scene again**,not only that but **it also appeals to a younger audience of new gamers**, while **Vanilla Wow main demographic is older**. <br>\n",
    "\n",
    "Only time will tell, but I don't think that **Vanilla Wow** has the power to retain massive viewership for a long period of time! (despite being awsome!)\n",
    "\n",
    "Wow will be divided into 4 stages of release of content, so it'd be safe to predict that during these releases of \"new old content\", we should see a shift in viewership on twitch!   \n",
    "\n",
    "\n",
    "<br> \n",
    "<br> \n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "*\"Propose a new section for the BI that offers a different perspective.\n",
    "   Assume that all the metrics present in the BI (game genres, publishers, channels, tournaments,chat, etc.) are available for all the platforms and date ranges.<br>What new insights could a business extract from this new section?\"*\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "A new section that I think would be interesting possible to be integrated right now in the BI with the data available, would be a **viewer dedicated section**. <br>\n",
    "<br>\n",
    "One of the **main goals of streaming** is delivering content to the maximum amount of viewers possible, maximizing the reach, whether it would be as a **personal brand** (streamers name) or a **sponsor brand**. <br>\n",
    "**Knowing your audience** looks like an important step in order to maximize your stream and brand value. This section could answer a **series of  questions** like:\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* **What's the average twitch's viewer sentiment towards a specific brand,stream or game? based on chat rooms** \n",
    "\n",
    "<br>\n",
    "\n",
    "* **How many active users on the platform?** \n",
    "\n",
    "<br>\n",
    "\n",
    "* **Whats the average length of stay of a viewer on twitch of a specific channel or game?**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "* **What's the percentage of total viwers by game genre**  \n",
    "\n",
    "<br>\n",
    "\n",
    "* **Whats the busiest time of the day, year week and month?**  \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "* **Top 10 words/expressions used in chatrooms** \n",
    "\n",
    "<br>\n",
    "\n",
    "* **Top 10 languages used by the audience in chat rooms(English, Spanish)** \n",
    "\n",
    "\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The data is already on the platform,**there seems to be a section for everybody , games , publisher, channels , brands** a section that seems to be missing here is the **audience** section. <br>\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "I think this is a section with huge potential and interest for all parties envolved in the platform!.\n",
    "\n",
    "\n",
    "# An extra feature on channel's searched.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Channel's chat level of sentiment** - In the **search** section, we can find the **chat** , there we can search only the channel and we'll have all of the messages that were displayed by user range input. \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**Message Reach** -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"chat.png\">\n",
    "\n",
    "\n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The percentage between the overall message views of the session's chat with the total of viewers on the channel**\n",
    "\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "\n",
    "****\n",
    "\n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Looking at the metrics that are available in the BI, think of a dataset(s) that you would use to apply Machine Learning to extract new information.\n",
    "### Explain what techniques you would use and how the new information would be valuable.<br><br>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an intereting oportunity to apply Machine Learning Techniques on the **Rankings Data Set** specially for Twitch, while analyzing Twitch data, I found a interesting **seasonal pattern** for the month of January, also , we have a rich data set for twitch counting with 7 years of data with monthly **data granularity** for all years, and daily for this year. <br>\n",
    "Here could be interesting in trying to apply different **Time Series models**, if done correctly we could even be able to **predict platform peaks** for instance, which would prove usefull for users who want to maximizer their viewership reach!    <br>\n",
    "\n",
    "\n",
    "\n",
    "Ideas -\n",
    "\n",
    "\n",
    "* Predict Air Time based on previous same content streams, type of game , day of the week.   \n",
    "\n",
    "* Predict \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
